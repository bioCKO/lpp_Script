
"""
Test output of Circular Consensus Sequence (CCS) pipelines.
"""

# XXX currently the pipeline output is defined as the pbreports report, which
# has the various statistics pre-calculated.  It is difficult to get at the
# final dataset directly, since the file ID will be different depending on
# whether the pipeline was run in chunked mode or not.

import subprocess
import tempfile
import unittest
import logging
import shutil
import json
import csv
import os.path as op
import os
import sys

import pysam

from pbcommand.models import FileTypes
from pbcore.io import ConsensusReadSet, FastaReader, FastaWriter, IndexedBamReader, SubreadSet

from pysiv2.custom.base import (TestReportStatistics, TestValuesLoader,
                                LoadResolvedToolContractMixin)
from pysiv2.utils import FastxStats
from pysiv2.custom import utils as u
from pysiv2.io.datastore import DataStore

MIN_CCS_MEAN_ACCURACY = 0.90
NRECORDS_MAX_ITER = 100
log = logging.getLogger(__name__)


class TestCCS(TestReportStatistics, LoadResolvedToolContractMixin):
    """
    Test output of the ``ccs`` report from ``pbreports``, plus additional
    validity tests on CCS output files.
    """
    REPORT_ID = "ccs"
    TEST_ID = "ccs"
    METRIC_IDS = [
        "total_number_of_ccs_bases",
        "mean_ccs_readlength",
        "number_of_ccs_reads",
        "mean_ccs_num_passes",
    ]

    @classmethod
    def _get_output_file(cls, file_type):
        for file_id, file_info in cls.datastore.get_file_dict().iteritems():
            if (file_info.file_type_id == FileTypes.GZIP.file_type_id and
                file_type.ext in file_info.file_id):
                return file_info.path
        raise IOError("bam2{f} gzipped file not found".format(
                      f=file_type.ext))

    @classmethod
    def getMetrics(cls):
        super(TestCCS, cls).getMetrics()
        subread_set = None
        for f_id, f_info in cls.datastore.get_file_dict().iteritems():
            if f_info.file_type_id == FileTypes.DS_SUBREADS.file_type_id:
                subread_set = f_info.path
                break
        if subread_set is None:
            subread_set = cls.entrypoints.data.get("eid_subread", None)
        with SubreadSet(subread_set) as subreads:
            cls.is_barcoded = subreads.isBarcoded
            for ext_res in subreads.externalResources:
                cls.barcode_set = ext_res.barcodes
                break
        for file_id, file_info in cls.datastore.get_file_dict().iteritems():
            if file_info.is_chunked:
                continue
            if file_info.file_type_id == FileTypes.DS_CCS.file_type_id:
                cls.final_ccs_file = file_info.path
                break
        fastq_file = fasta_file = None
        fastq_file = cls._get_output_file(FileTypes.FASTQ)
        fasta_file = cls._get_output_file(FileTypes.FASTA)
        assert not None in [fastq_file, fasta_file]
        for file_type, seq_file in zip([FileTypes.FASTQ, FileTypes.FASTA],
                                       [fastq_file, fasta_file]):
            stats = FastxStats(seq_file, file_type,
                               is_barcoded=cls.is_barcoded).get_stats()
            cls.metric_dict.update({
                '{i}_total_number_of_ccs_bases'.format(i=file_type.ext): stats['sum'],
                '{i}_mean_ccs_readlength'.format(i=file_type.ext): stats['avg'],
                '{i}_number_of_ccs_reads'.format(i=file_type.ext): stats['num'],
            })
        cls.loadRtcs() # from LoadResolvedToolContractMixin

    def _compare_fastx_output(self, file_type):
        for metric in ["total_number_of_ccs_bases",
                       "mean_ccs_readlength",
                       "number_of_ccs_reads"]:
            for expected, OP in self._expected_values_and_operators(metric):
                key = "%s_%s" % (file_type, metric)
                value = self.metric_dict[key]
                eqn = "%s .%s. %s" % (value, OP.__name__, expected)
                logging.info("Comparing values of %s: %s" % (metric, eqn))
                self.assertTrue(OP(value, expected),
                                "FAILED {i}: ! {e}".format(i=metric, e=eqn))

    def test_ccs_fastq_output(self):
        """
        Check that the CCS dataset and Fastq file have the same basic stats
        """
        self._compare_fastx_output("fastq")

    def test_ccs_fasta_output(self):
        """
        Check that the CCS dataset and FASTA file have the same basic stats
        """
        self._compare_fastx_output("fasta")

    @unittest.skip("DISABLED")
    def test_validity_ccs_accuracy(self):
        """
        check that ccs accuracy is greater than a preset threshold.  this can
        be specified in the 'ccs' section of test_values.json, otherwise the
        permissive default value of 0.90 will be used.
        """
        with ConsensusReadSet(self.final_ccs_file) as ds:
            values_sum = n_values = 0
            for rr in ds.resourceReaders():
                values_sum += rr.readQual.sum()
                n_values += len(rr)
            # XXX see BamAlignment.readScore docstring for explanation
            readScore = values_sum / n_values
            vmin = MIN_CCS_MEAN_ACCURACY
            if "min_ccs_mean_accuracy" in self.expected_values:
                vmin = self.expected_values["min_ccs_mean_accuracy"]
            self.assertGreater(readScore, vmin)

    def test_ccs_bam_index(self):
        """
        Test that the output includes .pbi index file(s).
        """
        with ConsensusReadSet(self.final_ccs_file) as ds:
            ds.assertIndexed()

    def test_ccs_barcoding_propagation(self):
        """
        Test that any BarcodeSet defined as an external resource of the
        subreads BAM file(s) in the input SubreadSet is also an external
        resource of the output ConsensusReadSet.
        """
        if self.is_barcoded:
            with ConsensusReadSet(self.final_ccs_file) as ccs:
                self.assertTrue(ccs.isBarcoded)
                for ext_res_out in ccs.externalResources:
                    self.assertEqual(self.barcode_set,
                                     ext_res_out.barcodes)
                if "barcodes" in self.expected_values:
                    barcodes = set()
                    for bam in ccs.resourceReaders():
                        bc_eq = bam.pbi.bcForward == bam.pbi.bcReverse
                        self.assertTrue(bc_eq.all())
                        barcodes.update(set(list(bam.pbi.bcForward)))
                    self.assertEqual(sorted(list(barcodes)),
                                     self.expected_values["barcodes"])
        else:
            raise unittest.SkipTest("SubreadSet was not barcoded, skipping")

    def test_ccs_report_barcode_table(self):
        """
        Check for barcoding table in CCS report (if input was barcoded).
        """
        if self.is_barcoded:
            bc_table = self.report.tables[1]
            self.assertEqual(bc_table.id, "ccs_barcodes")
            for col in bc_table.columns:
                if col.id == "number_of_ccs_reads":
                    self.assertTrue(all([x>0 for x in col.values]))
                    break
            else:
                self.fail("Can't find column number_of_ccs_reads")
        else:
            raise unittest.SkipTest("SubreadSet was not barcoded, skipping")

    def test_ccs_bam_np_is_at_least_npasses(self):
        """
        Check that the number of passes of each read in the ConsensusReadSet
        output is at least equal to the minimum specified in the resolved
        tool contract.
        """
        nchecked = nskipped = 0
        for rtc in self.resolved_tool_contracts:
            if rtc.task.task_id == "pbccs.tasks.ccs":
                min_passes = rtc.task.options["pbccs.task_options.min_passes"]
                with ConsensusReadSet(rtc.task.output_files[0]) as ccs:
                    for bam in ccs.resourceReaders():
                        if len(bam) > NRECORDS_MAX_ITER:
                            nskipped += 1
                        else:
                            for rec in bam:
                                np = rec.peer.opt("np")
                                self.assertTrue(np >= min_passes,
                                    "{r} has np {n} < {e}".format(r=rec.qName,
                                                                  n=np,
                                                                  e=min_passes))
                            nchecked += 1
        if nchecked == 0:
            if nskipped == 0:
                raise unittest.SkipTest("No CCS BAM files found")
            else:
                raise unittest.SkipTest("File size over limit - 'np' not checked")


@unittest.skip("DISABLED PENDING REVIEW")
class TestAccuracy(TestValuesLoader):
    """
    CURRENTLY DISABLED PENDING REVIEW
    Run 'ccscheck' against a reference FASTA to catch accuracy regressions.
    """

    @classmethod
    def setUpClass(cls):
        super(TestAccuracy, cls).setUpClass()
        ref_fasta = cls.test_values["ccs"].get("reference", None)
        cls.ref_csv = cls.test_values["ccs"].get("ccscheck_out", None)
        if cls.ref_csv is None:
            raise unittest.skipTest("No CSV file defined")
        ref_dir = op.dirname(ref_fasta)
        cls.run_dir = tempfile.mkdtemp()
        tmp_ref_fasta = op.join(cls.run_dir, op.basename(ref_fasta))
        shutil.copyfile(ref_fasta, tmp_ref_fasta)
        cls.ref_fasta = tmp_ref_fasta
        pysam.faidx(tmp_ref_fasta)
        cls.final_ccs_file = None
        for file_id, file_info in cls.datastore.get_file_dict().iteritems():
            if file_info.is_chunked:
                continue
            if file_info.file_type_id == FileTypes.DS_CCS.file_type_id:
                cls.final_ccs_file = file_info.path
                break
        cls.ccs_ds = ConsensusReadSet(cls.final_ccs_file)

    @classmethod
    def tearDownClass(cls):
        shutil.rmtree(cls.run_dir)

    def test_ccscheck_numerrors(self):
        if self.ref_fasta is None:
            raise unittest.SkipTest("Comparison FASTA file not specified")
        elif self.ref_csv is None:
            raise unittest.skipTest("No CSV file defined")
        elif not op.isfile(op.realpath(self.ref_fasta)):
            self.fail("{f} is not a file".format(f=self.ref_fasta))
        ref_lines = {}
        with open(self.ref_csv) as csv_ref:
            c = csv.reader(csv_ref, delimiter=',')
            for row in c:
                if row[0] != "Movie":
                    ref_lines[(row[0],row[1])] = row
        for i_file, file_name in enumerate(self.ccs_ds.toExternalFiles()):
            out_dir = op.join(self.run_dir, "out_{i}".format(i=i_file))
            args = ["ccscheck", file_name, out_dir, self.ref_fasta]
            assert subprocess.call(args) == 0, \
                "cmd '{a}' failed".format(a=" ".join(args))
            csv_file = op.join(out_dir, "zmws.csv")
            with open(csv_file) as f:
                c = csv.reader(f, delimiter=',')
                for row in c:
                    if row[0] != "Movie":
                        csv_ref = ref_lines.get((row[0], row[1]), None)
                        if csv_ref is None:
                            log.warn("{m}/{z} not found".format(
                                     m=row[0], z=row[1]))
                        else:
                            self.assertEqual(row, csv_ref)
